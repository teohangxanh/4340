setwd("D:/GitHub/4340")
# # Taking care of missing data
# # Find which columns have missing data
columnsWithMissingData <- c(colnames(x)[colSums(is.na(x)) > 0])
# Data preprocessing
# Importing the dataset
dataset = read.csv('data.csv')
# Drop unneccessary columns
drops <- c("ï..ID", "Name", "Photo", "Nationality", "Flag", "Club", "Club.Logo", "Position", "Jersey.Number", "Joined", "Loaned.From", "Contract.Valid.Until
")
x = dataset[ , !(names(dataset) %in% drops)]
# # Taking care of missing data
# # Find which columns have missing data
columnsWithMissingData <- c(colnames(x)[colSums(is.na(x)) > 0])
print(columnsWithMissingData)
for(i in 1:length(columnsWithMissingData))
for (j in 1:ncol(x))
# For columns of which x names are in columnsWithMissingData
if(columnsWithMissingData[i] %in% colnames(x))
# Find frequency of types in body type
w = table(columnsWithMissingData[i])
t = as.data.frame(w)
# # Sort the frequency of the table in descending order
t <- t[order(t$Freq),]
# Assign blank values to the most occured one
x$columnsWithMissingData[i][which(is.na(x$columnsWithMissingData[i]))] <- tail(t$Var1, n=1)
# Assign blank values to the most occured one
# dataset$Body.Type[which(is.na(dataset$Body.Type))] <- tail(t$Var1, n=1)
#
# dataset$Work.Rate[which(is.na(dataset$Work.Rate))] <- 'Medium/ Medium'
#
# # Encoding categorical data
# dataset$Preferred.Foot = factor(dataset$Preferred.Foot,
#                                 levels = c('Left', 'Right'),
#                                 labels = c(1, 2))
View(t)
# Approach 2: Remove rows with missing data
x <- na.omit(x)
# Data preprocessing
# Importing the dataset
dataset = read.csv('data.csv')
# Drop unneccessary columns
drops <- c("ï..ID", "Name", "Photo", "Nationality", "Flag", "Club", "Club.Logo", "Position", "Jersey.Number", "Joined", "Loaned.From", "Contract.Valid.Until
")
x = dataset[ , !(names(dataset) %in% drops)]
# Taking care of missing data
columnsWithMissingData <- c(colnames(x)[colSums(is.na(x)) > 0])
# Approach 1: Fill collumns with missing data by the most occurred ones
# Find which columns have missing data
# for(i in 1:length(columnsWithMissingData))
#   for (j in 1:ncol(x))
#     # For columns of which x names are in columnsWithMissingData
#     if(columnsWithMissingData[i] %in% colnames(x))
#
#       # Find frequency of types in body type
#       w = table(columnsWithMissingData[i])
#       t = as.data.frame(w)
#
#       # # Sort the frequency of the table in descending order
#       t <- t[order(t$Freq),]
#
#       # Assign blank values to the most occured one
#       x$columnsWithMissingData[i][which(is.na(x$columnsWithMissingData[i]))] <- tail(t$Var1, n=1)
# Approach 2: Remove rows with missing data
x <- na.omit(x)
# # Encoding categorical data
# dataset$Preferred.Foot = factor(dataset$Preferred.Foot,
#                                 levels = c('Left', 'Right'),
#                                 labels = c(1, 2))
dataset$Preferred.Foot = factor(dataset$Preferred.Foot,
levels = c('Left', 'Right'),
labels = c(1, 2))
x$Preferred.Foot = factor(x$Preferred.Foot,
levels = c('Left', 'Right'),
labels = c(1, 2))
View(x)
x$Work.Rate = factor(x$Work.Rate,
levels = c('Low/ Low', 'Low/ Medium', 'Low/ High',
'Medium/ Low', 'Medium/ Medium', 'Medium/ High',
'High/ Low', 'High/ Medium', 'High/ High'),
labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9))
View(x)
x$Work.Rate = factor(x$Work.Rate,
levels = c('Low/ Low', 'Low/ Medium', 'Low/ High',
'Medium/ Low', 'Medium/ Medium', 'Medium/ High',
'High/ Low', 'High/ Medium', 'High/ High'),
labels = c(2, 3, 4, 3, 4, 5, 4, 5, 6))
View(x)
x$Work.Rate = factor(x$Work.Rate,
levels = c('Low/ Low', 'Low/ Medium', 'Low/ High',
'Medium/ Low', 'Medium/ Medium', 'Medium/ High',
'High/ Low', 'High/ Medium', 'High/ High'),
labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9))
View(x)
View(dataset)
